{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Phase 3 Project - Chicago Traffic Crash Classification__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,\\\n",
    "precision_recall_fscore_support, fbeta_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "RandomizedSearchCV, cross_validate, cross_val_predict, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes = pd.read_csv('data/Traffic_Crashes_-_Crashes.csv', low_memory=False)\n",
    "people = pd.read_csv('data/Traffic_Crashes_-_People.csv', low_memory=False)\n",
    "#vehicles = pd.read_csv('Chicago-Crashes/data/Traffic_Crashes_-_Vehicles.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541142 entries, 0 to 541141\n",
      "Data columns (total 49 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   CRASH_RECORD_ID                541142 non-null  object \n",
      " 1   RD_NO                          536550 non-null  object \n",
      " 2   CRASH_DATE_EST_I               41029 non-null   object \n",
      " 3   CRASH_DATE                     541142 non-null  object \n",
      " 4   POSTED_SPEED_LIMIT             541142 non-null  int64  \n",
      " 5   TRAFFIC_CONTROL_DEVICE         541142 non-null  object \n",
      " 6   DEVICE_CONDITION               541142 non-null  object \n",
      " 7   WEATHER_CONDITION              541142 non-null  object \n",
      " 8   LIGHTING_CONDITION             541142 non-null  object \n",
      " 9   FIRST_CRASH_TYPE               541142 non-null  object \n",
      " 10  TRAFFICWAY_TYPE                541142 non-null  object \n",
      " 11  LANE_CNT                       198968 non-null  float64\n",
      " 12  ALIGNMENT                      541142 non-null  object \n",
      " 13  ROADWAY_SURFACE_COND           541142 non-null  object \n",
      " 14  ROAD_DEFECT                    541142 non-null  object \n",
      " 15  REPORT_TYPE                    527615 non-null  object \n",
      " 16  CRASH_TYPE                     541142 non-null  object \n",
      " 17  INTERSECTION_RELATED_I         122702 non-null  object \n",
      " 18  NOT_RIGHT_OF_WAY_I             25602 non-null   object \n",
      " 19  HIT_AND_RUN_I                  162942 non-null  object \n",
      " 20  DAMAGE                         541142 non-null  object \n",
      " 21  DATE_POLICE_NOTIFIED           541142 non-null  object \n",
      " 22  PRIM_CONTRIBUTORY_CAUSE        541142 non-null  object \n",
      " 23  SEC_CONTRIBUTORY_CAUSE         541142 non-null  object \n",
      " 24  STREET_NO                      541142 non-null  int64  \n",
      " 25  STREET_DIRECTION               541139 non-null  object \n",
      " 26  STREET_NAME                    541141 non-null  object \n",
      " 27  BEAT_OF_OCCURRENCE             541137 non-null  float64\n",
      " 28  PHOTOS_TAKEN_I                 6746 non-null    object \n",
      " 29  STATEMENTS_TAKEN_I             11007 non-null   object \n",
      " 30  DOORING_I                      1746 non-null    object \n",
      " 31  WORK_ZONE_I                    3412 non-null    object \n",
      " 32  WORK_ZONE_TYPE                 2696 non-null    object \n",
      " 33  WORKERS_PRESENT_I              843 non-null     object \n",
      " 34  NUM_UNITS                      541133 non-null  float64\n",
      " 35  MOST_SEVERE_INJURY             540019 non-null  object \n",
      " 36  INJURIES_TOTAL                 540030 non-null  float64\n",
      " 37  INJURIES_FATAL                 540030 non-null  float64\n",
      " 38  INJURIES_INCAPACITATING        540030 non-null  float64\n",
      " 39  INJURIES_NON_INCAPACITATING    540030 non-null  float64\n",
      " 40  INJURIES_REPORTED_NOT_EVIDENT  540030 non-null  float64\n",
      " 41  INJURIES_NO_INDICATION         540030 non-null  float64\n",
      " 42  INJURIES_UNKNOWN               540030 non-null  float64\n",
      " 43  CRASH_HOUR                     541142 non-null  int64  \n",
      " 44  CRASH_DAY_OF_WEEK              541142 non-null  int64  \n",
      " 45  CRASH_MONTH                    541142 non-null  int64  \n",
      " 46  LATITUDE                       538026 non-null  float64\n",
      " 47  LONGITUDE                      538026 non-null  float64\n",
      " 48  LOCATION                       538026 non-null  object \n",
      "dtypes: float64(12), int64(5), object(32)\n",
      "memory usage: 202.3+ MB\n"
     ]
    }
   ],
   "source": [
    "crashes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1195747 entries, 0 to 1195746\n",
      "Data columns (total 30 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   PERSON_ID              1195747 non-null  object \n",
      " 1   PERSON_TYPE            1195747 non-null  object \n",
      " 2   CRASH_RECORD_ID        1195747 non-null  object \n",
      " 3   RD_NO                  1185613 non-null  object \n",
      " 4   VEHICLE_ID             1172146 non-null  float64\n",
      " 5   CRASH_DATE             1195747 non-null  object \n",
      " 6   SEAT_NO                244512 non-null   float64\n",
      " 7   CITY                   879728 non-null   object \n",
      " 8   STATE                  890189 non-null   object \n",
      " 9   ZIPCODE                803192 non-null   object \n",
      " 10  SEX                    1177665 non-null  object \n",
      " 11  AGE                    852450 non-null   float64\n",
      " 12  DRIVERS_LICENSE_STATE  705542 non-null   object \n",
      " 13  DRIVERS_LICENSE_CLASS  608027 non-null   object \n",
      " 14  SAFETY_EQUIPMENT       1192258 non-null  object \n",
      " 15  AIRBAG_DEPLOYED        1173141 non-null  object \n",
      " 16  EJECTION               1181206 non-null  object \n",
      " 17  INJURY_CLASSIFICATION  1195154 non-null  object \n",
      " 18  HOSPITAL               215168 non-null   object \n",
      " 19  EMS_AGENCY             136061 non-null   object \n",
      " 20  EMS_RUN_NO             22281 non-null    object \n",
      " 21  DRIVER_ACTION          948962 non-null   object \n",
      " 22  DRIVER_VISION          948631 non-null   object \n",
      " 23  PHYSICAL_CONDITION     949646 non-null   object \n",
      " 24  PEDPEDAL_ACTION        22222 non-null    object \n",
      " 25  PEDPEDAL_VISIBILITY    22174 non-null    object \n",
      " 26  PEDPEDAL_LOCATION      22221 non-null    object \n",
      " 27  BAC_RESULT             950056 non-null   object \n",
      " 28  BAC_RESULT VALUE       1513 non-null     float64\n",
      " 29  CELL_PHONE_USE         1157 non-null     object \n",
      "dtypes: float64(4), object(26)\n",
      "memory usage: 273.7+ MB\n"
     ]
    }
   ],
   "source": [
    "people.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns with 80% or more of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[crashes, people]\n",
    "for df in df_list:\n",
    "    min_count =  int((20/100)*df.shape[0] + 1)\n",
    "    df = df.dropna(axis=1, thresh=min_count, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that will not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_mod = crashes.drop(['CRASH_DATE','RD_NO','REPORT_TYPE', 'DATE_POLICE_NOTIFIED', 'STREET_NO', \n",
    "              'STREET_DIRECTION', 'STREET_NAME', 'MOST_SEVERE_INJURY', 'INJURIES_TOTAL', 'INJURIES_FATAL',\n",
    "             'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT', \n",
    "             'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_mod = people.drop(['CITY', 'ZIPCODE','RD_NO'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195747, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541142, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes_mod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO INDICATION OF INJURY     468994\n",
       "NONINCAPACITATING INJURY     39675\n",
       "REPORTED, NOT EVIDENT        21763\n",
       "INCAPACITATING INJURY         9040\n",
       "FATAL                          547\n",
       "Name: MOST_SEVERE_INJURY, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes.MOST_SEVERE_INJURY.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up target variable:\n",
    " - 0: NO INDICATION OF INJURY, NONINCAPACITATING INJURY, REPORTED, NOT EVIDENT\n",
    " - 1: INCAPACITATING INJURY, FATAL\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes['TARGET']= crashes['MOST_SEVERE_INJURY'].map({'NO INDICATION OF INJURY': 0,\n",
    "                                                      'NONINCAPACITATING INJURY': 0,\n",
    "                                                      'REPORTED, NOT EVIDENT': 0,\n",
    "                                                      'INCAPACITATING INJURY': 1,\n",
    "                                                      'FATAL': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes.TARGET.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    531555\n",
       "1.0      9587\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = crashes.drop(['MOST_SEVERE_INJURY','INJURIES_TOTAL', 'INJURIES_FATAL','INJURIES_INCAPACITATING',\n",
    "                      'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT',\n",
    "                      'INJURIES_NO_INDICATION', 'TARGET', 'CRASH_RECORD_ID', 'CRASH_DATE', 'LATITUDE', \n",
    "                      'LONGITUDE','LOCATION'], axis=1)\n",
    "y = crashes['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FIRST SIMPLE MODEL - DUMMY CLASSIFIER__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "X_train_cat = X_train.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "                \n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first',\n",
    "                         sparse=False))\n",
    "])\n",
    "\n",
    "trans = ColumnTransformer(transformers=[\n",
    "    ('numerical', numerical_pipeline, X_train_nums.columns),\n",
    "    ('categorical', categorical_pipeline, X_train_cat.columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pipe = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('dc', DummyClassifier(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def print_cv_scores(pipe, X, y):\n",
    "    \n",
    "    # we pass in pipe to cross validate along with a feature list.\n",
    "    results = cross_validate(pipe, X, \n",
    "                                   y, \n",
    "                                   return_train_score=True)\n",
    "    \n",
    "    print(results['train_score'])\n",
    "    print(results['train_score'].mean())\n",
    "    print('##############')\n",
    "    print(results['test_score'])\n",
    "    print(results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_cv_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-631dda618ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_cv_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_cv_scores' is not defined"
     ]
    }
   ],
   "source": [
    "#print_cv_scores(dummy_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the people data, the target will be the injury classification so that the model will predict the severity of injuries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO INDICATION OF INJURY     1096283\n",
       "NONINCAPACITATING INJURY      55296\n",
       "REPORTED, NOT EVIDENT         32092\n",
       "INCAPACITATING INJURY         10827\n",
       "FATAL                           656\n",
       "Name: INJURY_CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_mod.INJURY_CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid too many repeated rows from crashes_dropped_df, we'll use the `CRASH_RECORD_ID` to only merge in rows from people_dropped_df where `DRIVER_TYPE == DRIVER`, then use the `VEHICLE_ID` to only merge in that driver's vehicle from vehicles_dropped_df.\n",
    "\n",
    "This will allow us to still retain over 75% of the rows from people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRIVER                 0.776163\n",
       "PASSENGER              0.204485\n",
       "PEDESTRIAN             0.011393\n",
       "BICYCLE                0.006911\n",
       "NON-MOTOR VEHICLE      0.000866\n",
       "NON-CONTACT VEHICLE    0.000181\n",
       "Name: PERSON_TYPE, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_mod.PERSON_TYPE.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_crashes_df = people_mod.merge(crashes_mod, on='CRASH_RECORD_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1195747 entries, 0 to 1195746\n",
      "Data columns (total 44 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   PERSON_ID                1195747 non-null  object \n",
      " 1   PERSON_TYPE              1195747 non-null  object \n",
      " 2   CRASH_RECORD_ID          1195747 non-null  object \n",
      " 3   VEHICLE_ID               1172146 non-null  float64\n",
      " 4   CRASH_DATE               1195747 non-null  object \n",
      " 5   SEAT_NO                  244512 non-null   float64\n",
      " 6   STATE                    890189 non-null   object \n",
      " 7   SEX                      1177665 non-null  object \n",
      " 8   AGE                      852450 non-null   float64\n",
      " 9   DRIVERS_LICENSE_STATE    705542 non-null   object \n",
      " 10  DRIVERS_LICENSE_CLASS    608027 non-null   object \n",
      " 11  SAFETY_EQUIPMENT         1192258 non-null  object \n",
      " 12  AIRBAG_DEPLOYED          1173141 non-null  object \n",
      " 13  EJECTION                 1181206 non-null  object \n",
      " 14  INJURY_CLASSIFICATION    1195154 non-null  object \n",
      " 15  DRIVER_ACTION            948962 non-null   object \n",
      " 16  DRIVER_VISION            948631 non-null   object \n",
      " 17  PHYSICAL_CONDITION       949646 non-null   object \n",
      " 18  BAC_RESULT               950056 non-null   object \n",
      " 19  POSTED_SPEED_LIMIT       1195747 non-null  int64  \n",
      " 20  TRAFFIC_CONTROL_DEVICE   1195747 non-null  object \n",
      " 21  DEVICE_CONDITION         1195747 non-null  object \n",
      " 22  WEATHER_CONDITION        1195747 non-null  object \n",
      " 23  LIGHTING_CONDITION       1195747 non-null  object \n",
      " 24  FIRST_CRASH_TYPE         1195747 non-null  object \n",
      " 25  TRAFFICWAY_TYPE          1195747 non-null  object \n",
      " 26  LANE_CNT                 446346 non-null   float64\n",
      " 27  ALIGNMENT                1195747 non-null  object \n",
      " 28  ROADWAY_SURFACE_COND     1195747 non-null  object \n",
      " 29  ROAD_DEFECT              1195747 non-null  object \n",
      " 30  CRASH_TYPE               1195747 non-null  object \n",
      " 31  INTERSECTION_RELATED_I   326381 non-null   object \n",
      " 32  HIT_AND_RUN_I            310957 non-null   object \n",
      " 33  DAMAGE                   1195747 non-null  object \n",
      " 34  PRIM_CONTRIBUTORY_CAUSE  1195747 non-null  object \n",
      " 35  SEC_CONTRIBUTORY_CAUSE   1195747 non-null  object \n",
      " 36  BEAT_OF_OCCURRENCE       1195735 non-null  float64\n",
      " 37  NUM_UNITS                1195747 non-null  float64\n",
      " 38  CRASH_HOUR               1195747 non-null  int64  \n",
      " 39  CRASH_DAY_OF_WEEK        1195747 non-null  int64  \n",
      " 40  CRASH_MONTH              1195747 non-null  int64  \n",
      " 41  LATITUDE                 1188743 non-null  float64\n",
      " 42  LONGITUDE                1188743 non-null  float64\n",
      " 43  LOCATION                 1188743 non-null  object \n",
      "dtypes: float64(8), int64(4), object(32)\n",
      "memory usage: 410.5+ MB\n"
     ]
    }
   ],
   "source": [
    "people_crashes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO INDICATION OF INJURY     1096283\n",
       "NONINCAPACITATING INJURY      55296\n",
       "REPORTED, NOT EVIDENT         32092\n",
       "INCAPACITATING INJURY         10827\n",
       "FATAL                           656\n",
       "Name: INJURY_CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_crashes_df.INJURY_CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_crashes_df['TARGET'] = people_crashes_df['INJURY_CLASSIFICATION'].map({np.nan: 0,\n",
    "                                                      'NO INDICATION OF INJURY': 0,\n",
    "                                                      'NONINCAPACITATING INJURY': 1,\n",
    "                                                      'REPORTED, NOT EVIDENT': 1,\n",
    "                                                      'INCAPACITATING INJURY': 2,\n",
    "                                                      'FATAL': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_crashes_df['CRASH_YEAR']=pd.to_datetime(people_crashes_df['CRASH_DATE']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    265694\n",
       "2019    263972\n",
       "2020    202084\n",
       "2017    185328\n",
       "2021    161704\n",
       "2016     96020\n",
       "2015     20931\n",
       "2014        11\n",
       "2013         3\n",
       "Name: CRASH_YEAR, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_crashes_df['CRASH_YEAR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls from BEAT_OF_OCCURRENCE\n",
    "people_crashes_df.dropna(subset = ['BEAT_OF_OCCURRENCE'], inplace=True)\n",
    "\n",
    "# Drop ages < 0 and ages = 0 for DRIVER\n",
    "people_crashes_df.loc[people_crashes_df.AGE < 0, 'AGE'] = np.nan\n",
    "people_crashes_df.loc[(people_crashes_df.AGE == 0) & (people_crashes_df.PERSON_TYPE == 'DRIVER'), 'AGE'] = np.nan\n",
    "people_crashes_df.dropna(subset = ['AGE'], inplace=True)\n",
    "\n",
    "# Drop POSTED_SPEED_LIMIT = 0 or not divisible by 5\n",
    "people_crashes_df.loc[people_crashes_df.POSTED_SPEED_LIMIT == 0, 'POSTED_SPEED_LIMIT'] = np.nan\n",
    "people_crashes_df.loc[(people_crashes_df.POSTED_SPEED_LIMIT % 5) != 0, 'POSTED_SPEED_LIMIT'] = np.nan\n",
    "people_crashes_df.dropna(subset = ['POSTED_SPEED_LIMIT'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train Test Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = people_crashes_df.drop(['PERSON_ID', 'CRASH_RECORD_ID','LANE_CNT', 'VEHICLE_ID','CRASH_DATE', 'CRASH_TYPE', 'LATITUDE', \n",
    "                            'INJURY_CLASSIFICATION','DRIVERS_LICENSE_STATE','LONGITUDE','LOCATION', 'TARGET'], axis=1)\n",
    "y = people_crashes_df['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reduce the features based on iterations of models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smaller = X_train[['PERSON_TYPE', 'SEX', 'SAFETY_EQUIPMENT', 'AGE', 'AIRBAG_DEPLOYED', \n",
    "                           'EJECTION', 'DRIVER_ACTION', 'SEAT_NO', 'LIGHTING_CONDITION', 'WEATHER_CONDITION', \n",
    "                           'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'DAMAGE', 'PRIM_CONTRIBUTORY_CAUSE', \n",
    "                           'BEAT_OF_OCCURRENCE', 'NUM_UNITS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_smaller = X_test[['PERSON_TYPE', 'SEX', 'SAFETY_EQUIPMENT', 'AGE', 'AIRBAG_DEPLOYED', \n",
    "#                            'EJECTION', 'DRIVER_ACTION', 'SEAT_NO', 'LIGHTING_CONDITION', 'WEATHER_CONDITION', \n",
    "#                            'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'DAMAGE', 'PRIM_CONTRIBUTORY_CAUSE', \n",
    "#                            'BEAT_OF_OCCURRENCE', 'NUM_UNITS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(X_train.columns)):\n",
    "#     print(X_train[X_train.columns[i]].value_counts())\n",
    "#     print(X_train[X_train.columns[i]].isna().sum())\n",
    "#     print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create functions to clean the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def seat_no_transformer(df):\n",
    "    '''\n",
    "    Set all SEAT_NO = 1 if PERSON_TYPE = 'DRIVER'\n",
    "    and fill the rest with 0.\n",
    "    '''\n",
    "    df.loc[(df.PERSON_TYPE == 'DRIVER'), 'SEAT_NO'] = 1\n",
    "    df['SEAT_NO'].fillna(value=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def age_transformer(df):\n",
    "#     df['AGE'][df.AGE < 0] = np.nan\n",
    "#     df.loc[(df.AGE==0)&(df.PERSON_TYPE == 'DRIVER')]['AGE'] = np.nan\n",
    "#     df.AGE.dropna(inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speed_transformer(df):\n",
    "#     df['POSTED_SPEED_LIMIT'][df.POSTED_SPEED_LIMIT == 0] = np.nan\n",
    "#     df['POSTED_SPEED_LIMIT'][(df.POSTED_SPEED_LIMIT %5) != 0] = np.nan\n",
    "#     df.POSTED_SPEED_LIMIT.dropna(inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_transformer(df):\n",
    "    '''\n",
    "    Extract and encode as a string the district\n",
    "    from BEAT_OF_OCCURRENCE.\n",
    "    '''\n",
    "    df['BEAT_OF_OCCURRENCE'] = df['BEAT_OF_OCCURRENCE'].apply(str)\n",
    "    df['BEAT_OF_OCCURRENCE'] = df['BEAT_OF_OCCURRENCE'].apply(lambda x: x[:-4])\n",
    "    # df.drop('BEAT_OF_OCCURRENCE', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def license_class_transformer(df):\n",
    "    '''\n",
    "    Bin all license classes into A, B, C, D, and OTHER\n",
    "    '''\n",
    "    dl_classes = ['A', 'B', 'C', 'D', np.nan]\n",
    "    df.loc[df['DRIVERS_LICENSE_CLASS'].isin(dl_classes) == False, 'DRIVERS_LICENSE_CLASS'] = 'OTHER'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_transformer(df):\n",
    "    '''\n",
    "    Ensure all columns are float, not int.\n",
    "    '''\n",
    "    for col in [df.select_dtypes('int64').columns]:\n",
    "        df[col] = df[col].astype('float64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_categories(df):\n",
    "    '''\n",
    "    Fill null values with given value for \n",
    "    unknown values in that column.\n",
    "    Drop all remaining nulls.\n",
    "    '''\n",
    "    df.fillna({#'STATE':'XX', \n",
    "               # 'DRIVERS_LICENSE_STATE':'XX', # This col now dropped before train-test-split\n",
    "               #'DRIVERS_LICENSE_CLASS': 'D', # Most common; D = 'normal' drivers license for cars\n",
    "               'EJECTION': 'UNKNOWN',\n",
    "               'DRIVER_ACTION': 'UNKNOWN',\n",
    "               #'DRIVER_VISION': 'UNKNOWN',\n",
    "               #'PHYSICAL_CONDITION': 'UNKNOWN',\n",
    "               'SAFETY_EQUIPMENT': 'USAGE_UNKNOWN',\n",
    "               'AIRBAG_DEPLOYED': 'DEPLOYMENT_UNKNOWN',\n",
    "               'SEX': 'UNKNOWN',\n",
    "               #'INTERSECTION_RELATED_I': 'N',\n",
    "               #'HIT_AND_RUN_I': 'N',\n",
    "               #'BAC_RESULT': 'TEST NOT OFFERED'\n",
    "              }, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ohe_cols = list(X_train_smaller.select_dtypes('object').columns)\n",
    "ohe_cols.append('BEAT_OF_OCCURRENCE')\n",
    "\n",
    "\n",
    "# OneHotEncode the columns as part of cleaning\n",
    "# to avoid needing to separate numerical and categorical\n",
    "# columns later\n",
    "ohe_col_trans = ColumnTransformer(transformers=\n",
    "                                     [('ohe', OneHotEncoder(drop='first', sparse=False), \n",
    "                                       ohe_cols)],\n",
    "                                 remainder='passthrough')\n",
    "\n",
    "# Apply all our cleaning functions, then finish with ohe\n",
    "cleaning_pipeline = Pipeline(steps=[\n",
    "    ('seat_no', FunctionTransformer(seat_no_transformer)),\n",
    "#     ('age', FunctionTransformer(age_transformer)),\n",
    "    ('beat', FunctionTransformer(beat_transformer)),\n",
    "#     ('speed', FunctionTransformer(speed_limit_transformer)),\n",
    "#     ('license', FunctionTransformer(license_class_transformer)),\n",
    "    ('fill_cat', FunctionTransformer(fill_categories)),\n",
    "    ('float', FunctionTransformer(to_float_transformer)),\n",
    "    ('col_trains', ohe_col_trans)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fit the cleaning pipeline to prepare data for a model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-37-41f05342683b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEAT_OF_OCCURRENCE'] = df['BEAT_OF_OCCURRENCE'].apply(str)\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/frame.py:3065: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#X_train_clean = cleaning_pipeline.fit_transform(X_train)\n",
    "#X_test_clean = cleaning_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-117-41f05342683b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BEAT_OF_OCCURRENCE'] = df['BEAT_OF_OCCURRENCE'].apply(str)\n"
     ]
    }
   ],
   "source": [
    "X_train_smaller_clean = cleaning_pipeline.fit_transform(X_train_smaller)\n",
    "#X_test_smaller_clean = cleaning_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Use SMOTE to resample to deal with the class imbalance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_smaller_clean, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LOGISTIC REGRESSION - ITERATION 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe1 = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression(class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_scores(pipe, X, y):\n",
    "    \n",
    "    # we pass in pipe to cross validate along with a feature list.\n",
    "    results = cross_validate(pipe, X, \n",
    "                                   y, \n",
    "                                   return_train_score=True)\n",
    "    \n",
    "    print(results['train_score'])\n",
    "    print(results['train_score'].mean())\n",
    "    print('##############')\n",
    "    print(results['test_score'])\n",
    "    print(results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74748576 0.74876755 0.74943934 0.74928585 0.74927638]\n",
      "0.7488509759823703\n",
      "##############\n",
      "[0.74679255 0.75107447 0.74639386 0.74685634 0.74993222]\n",
      "0.7482098857870877\n"
     ]
    }
   ],
   "source": [
    "print_cv_scores(lr_pipe1, X_train_smaller_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "y_pred = cross_val_predict(lr_pipe1, X_train_smaller_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.79395828, 0.14937041, 0.03379528, 0.02287603],\n",
       "       [0.29256945, 0.3720424 , 0.22806726, 0.10732088],\n",
       "       [0.15588433, 0.24761264, 0.35722932, 0.23927371],\n",
       "       [0.03791469, 0.05687204, 0.22274882, 0.68246445]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31395005064088854, 0.5514236147732384, 0.3215327917780622, None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_train, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LOGISTIC REGRESSION - ITERATION 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_pipe2 = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression(class_weight='balanced',\n",
    "                              max_iter=1000,\n",
    "                              random_state=42,\n",
    "                              C = 0.001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74921209 0.75071515 0.75098227 0.75160822 0.75120603]\n",
      "0.7507447522616543\n",
      "##############\n",
      "[0.74898534 0.75282073 0.74794077 0.74941592 0.75196555]\n",
      "0.7502256611709548\n"
     ]
    }
   ],
   "source": [
    "print_cv_scores(lr_pipe2, X_train_smaller_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(lr_pipe2.steps[1][1], X_train_smaller_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80079891, 0.14168365, 0.03083113, 0.02668632],\n",
       "       [0.30413399, 0.34354646, 0.22964575, 0.1226738 ],\n",
       "       [0.16785474, 0.22434432, 0.34418292, 0.26361802],\n",
       "       [0.04976303, 0.05924171, 0.18246445, 0.70853081]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meaghanross/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31244886950380907, 0.5492647724802594, 0.3191111100095438, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_train, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_logreg_coefs(cleaning_pipeline, model_pipeline, thresh=0.05, return_list=False):\n",
    "#     ohe_feature_names = cleaning_pipeline.steps[-1][1].get_feature_names()\n",
    "#     lr_coefs = model_pipeline.steps[1][1].coef_\n",
    "#     result = []\n",
    "    \n",
    "#     for i in range(len(lr_coefs)):\n",
    "#         print('Coefs for features in class ', i)\n",
    "#         for j in range(len(ohe_feature_names)):\n",
    "#             if abs(lr_coefs[i][j] >= thresh):\n",
    "#                 print(ohe_feature_names[j], ': ', lr_coefs[i][j])\n",
    "#                 result.append(ohe_feature_names[j], lr_coefs[i][j])\n",
    "#         print('='*30, '\\n')\n",
    "        \n",
    "#     if return_list:\n",
    "#         return result\n",
    "#     else:\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-4ff8374f4dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_logreg_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaning_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_pipe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-0aa39fc63fe2>\u001b[0m in \u001b[0;36mprint_logreg_coefs\u001b[0;34m(cleaning_pipeline, model_pipeline, thresh, return_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_logreg_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaning_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mohe_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlr_coefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# print_logreg_coefs(cleaning_pipeline, lr_pipe2, thresh=0.05, return_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipe = Pipeline(steps=[\n",
    "#     ('ss', StandardScaler()),\n",
    "#     ('lr', LogisticRegression(random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_grid = {\n",
    "#     'lr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#     'lr__penalty': ['l1', 'l2'],\n",
    "#     'lr__max_iter': list(range(100,800,100)),\n",
    "#     'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#     'lr__class_weight': ['balanced']\n",
    "# }\n",
    "# gs_pipe = GridSearchCV(estimator=model_pipe, param_grid=pipe_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_pipe.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_pipe.best_params_\n",
    "# print('Mean Accuracy: %.3f' % gs_pipe.best_score_)\n",
    "# print('Config: %s' % gs_pipe.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RANDOM FOREST - ITERATION 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(max_depth = 4,\n",
    "                                  n_estimators = 50,\n",
    "                                  random_state = 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59241822 0.59518873 0.59347444 0.59299088 0.59138929]\n",
      "0.5930923119657239\n",
      "##############\n",
      "[0.585245   0.59647907 0.59436954 0.59391561 0.59298316]\n",
      "0.5925984742183479\n"
     ]
    }
   ],
   "source": [
    "print_cv_scores(rf_pipe, X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(rf_pipe.steps[1][1], X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90715958, 0.05203099, 0.0103003 , 0.03050913],\n",
       "       [0.40517305, 0.2388567 , 0.18885965, 0.1671106 ],\n",
       "       [0.17407466, 0.18621392, 0.29190734, 0.34780408],\n",
       "       [0.00570291, 0.01147379, 0.05035303, 0.93247026]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_res, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5667378084169745, 0.5925984726652154, 0.5450818732642582, None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_res, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5925984726493148"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_res, y_pred, average='macro', beta=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=4, n_estimators=50,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.01989\n",
      "Feature: 1, Score: 0.00000\n",
      "Feature: 2, Score: 0.00019\n",
      "Feature: 3, Score: 0.00221\n",
      "Feature: 4, Score: 0.03170\n",
      "Feature: 5, Score: 0.01995\n",
      "Feature: 6, Score: 0.00000\n",
      "Feature: 7, Score: 0.00000\n",
      "Feature: 8, Score: 0.00000\n",
      "Feature: 9, Score: 0.00000\n",
      "Feature: 10, Score: 0.00000\n",
      "Feature: 11, Score: 0.00000\n",
      "Feature: 12, Score: 0.00000\n",
      "Feature: 13, Score: 0.00000\n",
      "Feature: 14, Score: 0.00000\n",
      "Feature: 15, Score: 0.00000\n",
      "Feature: 16, Score: 0.00253\n",
      "Feature: 17, Score: 0.00002\n",
      "Feature: 18, Score: 0.01056\n",
      "Feature: 19, Score: 0.00000\n",
      "Feature: 20, Score: 0.01100\n",
      "Feature: 21, Score: 0.07703\n",
      "Feature: 22, Score: 0.00000\n",
      "Feature: 23, Score: 0.00000\n",
      "Feature: 24, Score: 0.03511\n",
      "Feature: 25, Score: 0.00192\n",
      "Feature: 26, Score: 0.00000\n",
      "Feature: 27, Score: 0.03672\n",
      "Feature: 28, Score: 0.01684\n",
      "Feature: 29, Score: 0.00002\n",
      "Feature: 30, Score: 0.00125\n",
      "Feature: 31, Score: 0.01900\n",
      "Feature: 32, Score: 0.08764\n",
      "Feature: 33, Score: 0.00705\n",
      "Feature: 34, Score: 0.00000\n",
      "Feature: 35, Score: 0.01255\n",
      "Feature: 36, Score: 0.00668\n",
      "Feature: 37, Score: 0.08864\n",
      "Feature: 38, Score: 0.00000\n",
      "Feature: 39, Score: 0.00000\n",
      "Feature: 40, Score: 0.00000\n",
      "Feature: 41, Score: 0.00098\n",
      "Feature: 42, Score: 0.00343\n",
      "Feature: 43, Score: 0.00023\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00001\n",
      "Feature: 47, Score: 0.00003\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.01592\n",
      "Feature: 50, Score: 0.00494\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: 0.00000\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.00223\n",
      "Feature: 55, Score: 0.00946\n",
      "Feature: 56, Score: 0.00000\n",
      "Feature: 57, Score: 0.07805\n",
      "Feature: 58, Score: 0.00000\n",
      "Feature: 59, Score: 0.04112\n",
      "Feature: 60, Score: 0.00000\n",
      "Feature: 61, Score: 0.00000\n",
      "Feature: 62, Score: 0.00000\n",
      "Feature: 63, Score: 0.00512\n",
      "Feature: 64, Score: 0.00000\n",
      "Feature: 65, Score: 0.00000\n",
      "Feature: 66, Score: 0.00000\n",
      "Feature: 67, Score: 0.00000\n",
      "Feature: 68, Score: 0.00003\n",
      "Feature: 69, Score: 0.00026\n",
      "Feature: 70, Score: 0.00000\n",
      "Feature: 71, Score: 0.00011\n",
      "Feature: 72, Score: 0.00000\n",
      "Feature: 73, Score: 0.00000\n",
      "Feature: 74, Score: 0.03435\n",
      "Feature: 75, Score: 0.00203\n",
      "Feature: 76, Score: 0.00005\n",
      "Feature: 77, Score: 0.00013\n",
      "Feature: 78, Score: 0.00000\n",
      "Feature: 79, Score: 0.00122\n",
      "Feature: 80, Score: 0.00810\n",
      "Feature: 81, Score: 0.02759\n",
      "Feature: 82, Score: 0.03500\n",
      "Feature: 83, Score: 0.00000\n",
      "Feature: 84, Score: 0.00000\n",
      "Feature: 85, Score: 0.00000\n",
      "Feature: 86, Score: 0.00000\n",
      "Feature: 87, Score: 0.03660\n",
      "Feature: 88, Score: 0.00000\n",
      "Feature: 89, Score: 0.00007\n",
      "Feature: 90, Score: 0.00016\n",
      "Feature: 91, Score: 0.00059\n",
      "Feature: 92, Score: 0.00102\n",
      "Feature: 93, Score: 0.00000\n",
      "Feature: 94, Score: 0.00000\n",
      "Feature: 95, Score: 0.00055\n",
      "Feature: 96, Score: 0.00000\n",
      "Feature: 97, Score: 0.00105\n",
      "Feature: 98, Score: 0.00000\n",
      "Feature: 99, Score: 0.00114\n",
      "Feature: 100, Score: 0.00000\n",
      "Feature: 101, Score: 0.00096\n",
      "Feature: 102, Score: 0.00000\n",
      "Feature: 103, Score: 0.00000\n",
      "Feature: 104, Score: 0.00000\n",
      "Feature: 105, Score: 0.00000\n",
      "Feature: 106, Score: 0.00000\n",
      "Feature: 107, Score: 0.00000\n",
      "Feature: 108, Score: 0.00000\n",
      "Feature: 109, Score: 0.02115\n",
      "Feature: 110, Score: 0.04796\n",
      "Feature: 111, Score: 0.00000\n",
      "Feature: 112, Score: 0.00000\n",
      "Feature: 113, Score: 0.00000\n",
      "Feature: 114, Score: 0.00000\n",
      "Feature: 115, Score: 0.00026\n",
      "Feature: 116, Score: 0.00287\n",
      "Feature: 117, Score: 0.00000\n",
      "Feature: 118, Score: 0.00009\n",
      "Feature: 119, Score: 0.00000\n",
      "Feature: 120, Score: 0.00000\n",
      "Feature: 121, Score: 0.00000\n",
      "Feature: 122, Score: 0.00001\n",
      "Feature: 123, Score: 0.00016\n",
      "Feature: 124, Score: 0.00000\n",
      "Feature: 125, Score: 0.00165\n",
      "Feature: 126, Score: 0.00000\n",
      "Feature: 127, Score: 0.00009\n",
      "Feature: 128, Score: 0.00413\n",
      "Feature: 129, Score: 0.00298\n",
      "Feature: 130, Score: 0.00000\n",
      "Feature: 131, Score: 0.00245\n",
      "Feature: 132, Score: 0.00119\n",
      "Feature: 133, Score: 0.00297\n",
      "Feature: 134, Score: 0.00000\n",
      "Feature: 135, Score: 0.00000\n",
      "Feature: 136, Score: 0.00042\n",
      "Feature: 137, Score: 0.00000\n",
      "Feature: 138, Score: 0.00011\n",
      "Feature: 139, Score: 0.00000\n",
      "Feature: 140, Score: 0.00796\n",
      "Feature: 141, Score: 0.00000\n",
      "Feature: 142, Score: 0.00000\n",
      "Feature: 143, Score: 0.00000\n",
      "Feature: 144, Score: 0.00000\n",
      "Feature: 145, Score: 0.00000\n",
      "Feature: 146, Score: 0.00471\n",
      "Feature: 147, Score: 0.00058\n",
      "Feature: 148, Score: 0.00017\n",
      "Feature: 149, Score: 0.00002\n",
      "Feature: 150, Score: 0.00006\n",
      "Feature: 151, Score: 0.00104\n",
      "Feature: 152, Score: 0.00002\n",
      "Feature: 153, Score: 0.00001\n",
      "Feature: 154, Score: 0.00023\n",
      "Feature: 155, Score: 0.00016\n",
      "Feature: 156, Score: 0.00000\n",
      "Feature: 157, Score: 0.00203\n",
      "Feature: 158, Score: 0.00041\n",
      "Feature: 159, Score: 0.00001\n",
      "Feature: 160, Score: 0.00007\n",
      "Feature: 161, Score: 0.00000\n",
      "Feature: 162, Score: 0.00000\n",
      "Feature: 163, Score: 0.00000\n",
      "Feature: 164, Score: 0.00016\n",
      "Feature: 165, Score: 0.00203\n",
      "Feature: 166, Score: 0.00004\n",
      "Feature: 167, Score: 0.00037\n",
      "Feature: 168, Score: 0.00264\n",
      "Feature: 169, Score: 0.00050\n",
      "Feature: 170, Score: 0.00010\n",
      "Feature: 171, Score: 0.00070\n",
      "Feature: 172, Score: 0.02778\n",
      "Feature: 173, Score: 0.05866\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "importance = rf_pipe[1].feature_importances_\n",
    "ohe_feature_names = cleaning_pipeline.steps[-1][1].get_feature_names()\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# for i in range(len(importance)):\n",
    "#     if importance >= 0.05:\n",
    "#         print(ohe_feature_names[i], ': ', importance[i])\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohe__x4_UNKNOWN'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.08864\n",
    "ohe_feature_names[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohe__x3_DID NOT DEPLOY'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.08764\n",
    "ohe_feature_names[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohe__x6_DARKNESS, LIGHTED ROAD'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.07805\n",
    "ohe_feature_names[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohe__x2_SAFETY BELT USED'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.07703\n",
    "ohe_feature_names[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUM_UNITS'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.05866\n",
    "ohe_feature_names[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohe__x10_OVER $1,500'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score: 0.04796\n",
    "ohe_feature_names[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = cleaning_pipeline.steps[-1][1].get_feature_names()\n",
    "importance = [0.00254953, 0., 0.00233605, 0.00184723, 0.00097822, 0.00190925, 0.00063667, 0., 0.00207959, 0.00255143, 0., 0.00347863, 0.00226279, 0.019971, 0.00513911, 0., 0.00307888, 0.00187971, 0.00106023, 0.00102159, 0., 0.001242, 0.00136372, 0.00363245, 0.00165718, 0.0008518, 0., 0.0026852, 0., 0.00122229, 0.00111545, 0.00087373, 0.00911209, 0.0021856, 0.00044858, 0.00141463, 0.00124821, 0.00159017, 0., 0., 0., 0.00283378, 0.00171399, 0., 0.00199945, 0., 0.00118223, 0.00668535, 0., 0.00109466, 0.00401093, 0.00388916, 0.00272809, 0.01884322, 0.0045156, 0.00133088, 0., 0.00217315, 0.00772509, 0.0006892, 0.00263684, 0.01616743, 0.00812377, 0.00607146, 0., 0.00184517, 0.01411981, 0.00183418, 0.01307631, 0.00462931, 0.00542847, 0.01481777, 0.00219632, 0.00650142, 0.00336755, 0.06709845, 0.01570165, 0.0232122, 0.018059, 0.00679315, 0.00429122, 0.00489835, 0.00014759, 0.00165096, 0.00513983, 0.0291157, 0., 0.00671592, 0.00109376, 0.00371024, 0.00182787, 0.0051496, 0.01043787, 0.00372879, 0., 0.00559065, 0.01502675, 0.00993086, 0.00306601, 0.00369758, 0.02638649, 0., 0.00930436, 0.00256558, 0.00698451, 0.00583299, 0.0006391, 0.00265303,\n",
    " 0.00595531, 0.00678822, 0.00479762, 0.00296563, 0.00327525, 0.00279237,\n",
    " 0.00119998, 0.00966071, 0.00869574, 0.01835277, 0.01679247, 0.00308825,\n",
    " 0.00769471, 0.00518557, 0.01508538, 0.0037915,  0.0202597,  0.02124231,\n",
    " 0.00208727, 0.00147029, 0.00210141, 0.0062456,  0.00509456, 0.00592563,\n",
    " 0.00197763, 0.00795799, 0.00341921, 0.00718072, 0.01116631, 0.00868733,\n",
    " 0.01067301, 0.00586468, 0.00808448, 0.00534105, 0.01213205, 0.00776362,\n",
    " 0.01058323, 0.00266318, 0.00400647, 0.00865966, 0.00993486, 0.00619971,\n",
    " 0.00205991, 0.02401683, 0.00155812, 0.00779086, 0.00091193, 0.00621508,\n",
    " 0.00085267, 0.00121016, 0.00165691, 0.00142914, 0.00274774, 0.02355196,\n",
    " 0.00613796, 0.00533831, 0.00463595, 0.00795607, 0.00843228, 0.01086943,\n",
    " 0.00825049, 0.01543103]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    if v > 0.0001:\n",
    "        print('Feature: %s, Score: %.5f' % (feature_name[i],v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XGBoost Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2236052, 174)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(random_state=42,\n",
    "                          max_depth = 5,\n",
    "                          tree_method='hist',\n",
    "                          n_estimators = 50,\n",
    "                          n_jobs = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=5, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=50,\n",
       "                               n_jobs=-1, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='hist',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipe.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83184531 0.81999462 0.82042796 0.82094618 0.82140401]\n",
      "0.8229236178309695\n",
      "##############\n",
      "[0.76820561 0.83160745 0.83120011 0.83187317 0.83183516]\n",
      "0.8189442991824585\n"
     ]
    }
   ],
   "source": [
    "print_cv_scores(xgb_pipe, X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: ohe__x0_PASSENGER, Score: 0.01411\n",
      "Feature: ohe__x1_M, Score: 0.01960\n",
      "Feature: ohe__x2_SAFETY BELT USED, Score: 0.05224\n",
      "Feature: ohe__x2_USAGE UNKNOWN, Score: 0.01290\n",
      "Feature: ohe__x3_DEPLOYMENT UNKNOWN, Score: 0.01799\n",
      "Feature: ohe__x3_DID NOT DEPLOY, Score: 0.04446\n",
      "Feature: ohe__x3_NOT APPLICABLE, Score: 0.03277\n",
      "Feature: ohe__x4_TOTALLY EJECTED, Score: 0.01490\n",
      "Feature: ohe__x4_TRAPPED/EXTRICATED, Score: 0.01133\n",
      "Feature: ohe__x4_UNKNOWN, Score: 0.01894\n",
      "Feature: ohe__x5_NONE, Score: 0.01294\n",
      "Feature: ohe__x5_TOO FAST FOR CONDITIONS, Score: 0.01211\n",
      "Feature: ohe__x6_DARKNESS, LIGHTED ROAD, Score: 0.02240\n",
      "Feature: ohe__x6_DAYLIGHT, Score: 0.01027\n",
      "Feature: ohe__x7_CLEAR, Score: 0.01593\n",
      "Feature: ohe__x8_FIXED OBJECT, Score: 0.03136\n",
      "Feature: ohe__x8_PEDALCYCLIST, Score: 0.01727\n",
      "Feature: ohe__x8_REAR END, Score: 0.01182\n",
      "Feature: ohe__x8_SIDESWIPE SAME DIRECTION, Score: 0.01514\n",
      "Feature: ohe__x9_NOT DIVIDED, Score: 0.01184\n",
      "Feature: ohe__x10_OVER $1,500, Score: 0.02026\n",
      "Feature: ohe__x11_FAILING TO YIELD RIGHT-OF-WAY, Score: 0.01518\n",
      "Feature: ohe__x11_PHYSICAL CONDITION OF DRIVER, Score: 0.01492\n",
      "Feature: ohe__x12_16, Score: 0.01171\n",
      "Feature: ohe__x12_7, Score: 0.01126\n"
     ]
    }
   ],
   "source": [
    "feature_name = cleaning_pipeline.steps[-1][1].get_feature_names()\n",
    "importance = xgb_pipe[1].feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    if v > 0.01:\n",
    "        print('Feature: %s, Score: %.5f' % (feature_name[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
